{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Film production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0.1 Business Understanding\n",
    "\n",
    "One of the most well-known forms of art is film production, which has millions of spectators worldwide. There are many ways that movies can be communicated to viewers as a result of the development of various films genres over time.\n",
    "\n",
    "I intend to analyse on the categories of movies that are doing the best at the box office and to translate findings into useful advice for my client and the factors to consider for a movie producer to ensure maximum return on investment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0.2 Data Understanding\n",
    "\n",
    "The dataset for this project was compiled from several sources.The data have been collected over the past years and its from box office and the IMDB database.\n",
    "These are the sites with accurate movie data and are frequently updated hence the choice for these sites.\n",
    "These are the datasets I will use for my analysis. \n",
    "* Box Office Mojo data\n",
    "* IMDB  data  \n",
    "* popular movies data\n",
    "* top rated movies data\n",
    "\n",
    "The finals datasets I used for my analysis had 1517 rows, and 9 columns.These were the features for my analysis:\n",
    " * release_date \n",
    " * original_title'\n",
    " * production_budget\n",
    " * domestic_gross\n",
    " * worldwide_gross\n",
    " * averagerating\n",
    " * genres\n",
    " * numvotes\n",
    " * runtime_minutes\n",
    " * studio\n",
    "\n",
    "Release_date I used to check on how the genres have been changing over the years as well as how the profits have been chaging over time.\n",
    "\n",
    "Original title was the unique identifier for all the movies in my dataset.I used this to merge most of the datasets and to check for duplicates.\n",
    "\n",
    "Production budget was crucial for my analysis,I used it for cmparison of how budgets for genres differed at to clasify the top 100 most expensive movies, and to find the correlation between domestic gross.\n",
    "\n",
    "To analyse profit making movies I used the domestic gross to classify movies as either profit making or loss.\n",
    "\n",
    "The average rating was to classify movies based on their popularity and how they are rated.\n",
    "\n",
    "Genres column was to check how gross changes per movie genre\n",
    "\n",
    "Runtime in minutes was to analyse how movie duration has been changing over time and classify movies.\n",
    "\n",
    "studio feature was to compare and how it relates to the the worlwide gross."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Data Preparation Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has to be prepared before the anlysys begins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0.1 Loading Libraries\n",
    "All important libraries that I used in my anlysis and connecting to the sqllite database to access the im dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> data sets merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sqlite3\n",
    "from dateutil import parser\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0.2 Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of the data sets.\n",
    "  \n",
    "#box office gross dataset\n",
    "box_office_df = pd.read_csv('Data/bom.movie_gross.csv.gz')\n",
    "\n",
    "#Teddy Newton movie budgets dataset\n",
    "movie_budgets_df = pd.read_csv('Data/tn.movie_budgets.csv.gz')\n",
    "\n",
    "#the movie data base dataset\n",
    "tmdb_df = pd.read_csv('Data/tmdb.movies.csv.gz')\n",
    "\n",
    "#Rotten Tomatoes reviews dataset\n",
    "rt_reviews_df = pd.read_csv('Data/rt.reviews.tsv.gz', sep='\\t', encoding = 'unicode_escape')\n",
    "\n",
    "#Rotten Tomatoes movie info dataset\n",
    "rt_movie_info_df = pd.read_csv('Data/rt.movie_info.tsv.gz', sep='\\t', encoding = 'unicode_escape')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### 2.0.3 SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to database\n",
    "conn = sqlite3.Connection(\"Data/im.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read sqlite query results into a pandas DataFrame\n",
    "# joining the two tables using the movie_id key\n",
    "\n",
    "joint_query = \"\"\"\n",
    "SELECT *\n",
    "FROM movie_basics\n",
    "JOIN movie_ratings USING (movie_id)\n",
    ";\n",
    "\"\"\"\n",
    "sql_data = pd.read_sql(joint_query, conn)\n",
    "DataOne = sql_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0.3.1 dataOne preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">##### dataOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to overview the data\n",
    "\n",
    "def shape_info(my_df):\n",
    "    print(f\"data frame shape and information:\\nrows:    {my_df.shape[0]}\\ncolumns:    {my_df.shape[1]}\")\n",
    "    print()\n",
    "    return my_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset information\n",
    "shape_info(DataOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function columns datatypes\n",
    "\n",
    "def columns_dtypes(my_df):\n",
    "    print(f\"Numerical columns:{len(list(my_df.select_dtypes(include= np.number)))}\")\n",
    "    print(f\"Categorical columns:{len(list(my_df.select_dtypes(include= 'object')))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check datatypes\n",
    "columns_dtypes(DataOne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0.3.2 dataOne cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check all columns distribution plot\n",
    "\n",
    "# def dist_check(my_data):\n",
    "#     plt.figure(figsize=(20,22))\n",
    "#     for i in range(1,13):\n",
    "#         plt.subplot(5, 4, i)\n",
    "#         sns.histplot(my_data[my_data.columns[i]], kde=True)\n",
    "        \n",
    "# #check distribution data\n",
    "# dist_check(DataOne)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### how are our features distrubuted\n",
    "def dist_check(my_data):\n",
    "    num_cols = my_data.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "    ncols = len(num_cols)\n",
    "    plt.figure(figsize=(20, int(22/4 * (ncols/4 + 1))))\n",
    "    for i, col in enumerate(num_cols):\n",
    "        plt.subplot(ncols//4 + 1, 4, i + 1)\n",
    "        sns.histplot(my_data[col], kde=True)\n",
    "        plt.title(col)\n",
    "dist_check(DataOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data(my_data):\n",
    "    percent_missing = round(my_data.isnull().sum() * 100 / len(my_data),2)\n",
    "    missing_value_df = pd.DataFrame(percent_missing,columns=['perc_missing'])\n",
    "    duplicate_rows = my_data.duplicated().sum()\n",
    "    print(f\"duplicates: {duplicate_rows}\")\n",
    "    print('    *** *** ***    ')\n",
    "    print(f\"null values percentage per column:\\n{missing_value_df}\")\n",
    "    most_missing_col = missing_value_df[missing_value_df['perc_missing'] == missing_value_df['perc_missing'].max()].index[0]\n",
    "    print(f\"Most missing values column: {most_missing_col}\")\n",
    "    return most_missing_col, missing_value_df, duplicate_rows\n",
    "\n",
    "# Example usage\n",
    "most_missing_col, missing_value_df, duplicate_rows = validate_data(DataOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check duplicates and null\n",
    "\n",
    "def check_duplicates_missing(dataframe):\n",
    "    # calculate percentage of missing values\n",
    "    percent_missing = dataframe.isnull().mean().round(4) * 100\n",
    "    #calculate percentage of duplicate rows\n",
    "    percent_duplicates = dataframe.duplicated().mean() * 100\n",
    "    # create result dataframe\n",
    "    result = pd.DataFrame({'Missing Values %': percent_missing, 'Duplicate Values %': percent_duplicates})\n",
    "    # find column with most missing values\n",
    "    if percent_missing.max() !=0:\n",
    "        column_most_missing = percent_missing.idxmax()\n",
    "        print(f\"{(column_most_missing).capitalize()} is the column with most missing values:\")\n",
    "        print()\n",
    "    else:\n",
    "        print(\"No column with missing values\")\n",
    "    if percent_duplicates.max() !=0:\n",
    "        column_most_duplicates = percent_duplicates.idxmax()\n",
    "        print(\"Column with most duplicates:\",column_most_duplicates)\n",
    "    else:\n",
    "        print(\"No duplicates\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_duplicates_missing(DataOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function to column with most null values form data frame\n",
    "\n",
    "# def find_null_columns(df):\n",
    "#     null_cols = df.isnull().sum()\n",
    "#     most_null_col = null_cols[null_cols == null_cols.max()].index[0]\n",
    "#     return most_null_col\n",
    "\n",
    "# # calling the funtion\n",
    "# print(find_null_columns(DataOne))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions used to clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect outliers\n",
    "def detect_outliers_zscore(data, threshold=3):\n",
    "    \"\"\"\n",
    "    Detect outliers in a pandas DataFrame using Z-score method\n",
    "    :param data: pandas DataFrame\n",
    "    :param threshold: Z-score threshold, default is 3\n",
    "    :return: pandas DataFrame indicating the outliers (True)\n",
    "    \"\"\"\n",
    "    # Select only the numerical columns\n",
    "    num_cols = data.select_dtypes(include=np.number).columns\n",
    "    num_data = data[num_cols]\n",
    "    \n",
    "    # Calculate Z-scores of each numerical column\n",
    "    z_scores = np.abs(num_data - num_data.mean()) / num_data.std()\n",
    "    \n",
    "    # Create a mask indicating the outliers\n",
    "    outlier_mask = z_scores > threshold\n",
    "    \n",
    "    return outlier_mask\n",
    "\n",
    "def show_outliers_perc(data):\n",
    "    \"\"\"\n",
    "    Display the percentage of outliers per column in a pandas DataFrame\n",
    "    :param data: pandas DataFrame\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    outlier_mask = detect_outliers_zscore(data)\n",
    "    outlier_perc = 100 * outlier_mask.mean().round(2)\n",
    "    print(f'Percentage of outliers per numerical column: \\n{outlier_perc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the percentage of outliers per numerical column\n",
    "show_outliers_perc(DataOne)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_outliers_zscore(df, threshold=3):\n",
    "#     numerical_cols = df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "#     fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#     for col in numerical_cols:\n",
    "#         mean = df[col].mean()\n",
    "#         std = df[col].std()\n",
    "#         z_scores = (df[col] - mean) / std\n",
    "#         outliers = df[np.abs(z_scores) > threshold]\n",
    "\n",
    "#         sns.boxplot(x=df[col], ax=ax)\n",
    "#         sns.stripplot(x=outliers[col], color='red', ax=ax)\n",
    "#     plt.rcParams[\"axes.grid\"] = True\n",
    "#     ax.set_title(\"Outliers\")\n",
    "#     ax.set_xlabel(\"Features\")\n",
    "#     plt.show()\n",
    "\n",
    "# visualize_outliers_zscore(DataOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize outliers\n",
    "# import seaborn as sns\n",
    "\n",
    "# def visualize_outliers_boxplot(data):    \n",
    "#     # Select only the numerical columns\n",
    "#     num_cols = data.select_dtypes(include=np.number).columns\n",
    "#     num_data = data[num_cols]\n",
    "    \n",
    "#     # Set the style of the plots to whitegrid\n",
    "#     sns.set_style('whitegrid')\n",
    "\n",
    "#     # Plot box plots for each numerical column\n",
    "#     plt.rcParams[\"axes.grid\"] = True\n",
    "#     plt.figure(figsize=(15, 10))\n",
    "#     for i, col in enumerate(num_cols):\n",
    "#         plt.subplot(3, 3, i+1)\n",
    "#         sns.boxplot(data=num_data, x=num_data.index, y=col, fliersize=2.5)\n",
    "#         plt.title(col)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize outliers per column\n",
    "# def visualize_outliers_zscore(df, threshold=3):\n",
    "#     numerical_cols = df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "#     plt.rcParams[\"axes.grid\"] = True\n",
    "#     for col in numerical_cols:\n",
    "#         mean = df[col].mean()\n",
    "#         std = df[col].std()\n",
    "#         z_scores = (df[col] - mean) / std\n",
    "#         outliers = df[np.abs(z_scores) > threshold]\n",
    "\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#         sns.boxplot(x=df[col], ax=ax)\n",
    "#         sns.stripplot(x=outliers[col], color='red', ax=ax)\n",
    "#         ax.set_title(f\"Outliers in {col.title()}\")\n",
    "#         ax.set_xlabel(col)\n",
    "#         plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_outliers_zscore(df, threshold=3):\n",
    "    plt.rcParams[\"axes.grid\"] = True\n",
    "    numerical_cols = df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "    for col in numerical_cols:\n",
    "        mean = df[col].mean()\n",
    "        std = df[col].std()\n",
    "        z_scores = (df[col] - mean) / std\n",
    "        outliers = df[np.abs(z_scores) > threshold]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        sns.boxenplot(df[col], ax=ax)\n",
    "        ax.scatter(x=outliers.index, y=outliers[col], color='red', s=50)\n",
    "        ax.set_title(f\"Outliers in {col.title()}\")\n",
    "        ax.set_xlabel(col)\n",
    "        plt.show()\n",
    "\n",
    "visualize_outliers_zscore(DataOne)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corre_plot(df, col=None):\n",
    "    plt.rcParams[\"axes.grid\"] = True\n",
    "    corr = df.corr()\n",
    "    if col:\n",
    "        corr = corr[col].drop(col)\n",
    "        corr = corr[abs(corr) > 0.5].sort_values(ascending=False)\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(corr, mask=mask, annot=True, cmap='coolwarm',linewidths=0.5)\n",
    "    plt.title(\"Correlation\", fontsize=18)\n",
    "    # show plot\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corre_plot(DataOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation ascending  oeder\n",
    "def visualize_correlation(df, column):\n",
    "    plt.style.use([])\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    heatmap = sns.heatmap(df.corr()[[column]].sort_values(by=column, ascending=False),\n",
    "                          vmin=-1, vmax=1, annot=True, cmap=None)\n",
    "    heatmap.set_title(f'Features Correlating with {column}', fontdict={'fontsize':18}, pad=16)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0.1 combining of the data sets to a final data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the data sets were all combied on common keys before cleaning of the data\n",
    "\n",
    "joint_query.dropna(inplace = True)\n",
    "\n",
    "box_office_df.dropna(inplace = True)\n",
    "\n",
    "box_office_df.rename(columns = {'title':'original_title'}, inplace = True)\n",
    "\n",
    "combined_data_1 = pd.merge(joint_query, box_office_df, how='inner', on='original_title')\n",
    "\n",
    "movie_budgets_df.dropna(inplace = True)\n",
    "\n",
    "movie_budgets_df.rename(columns = {'movie':'original_title'}, inplace = True)\n",
    " \n",
    "# Find the columns that aren't in the first DataFrame\n",
    "different_cols = combined_data_1.columns.difference(movie_budgets_df.columns)\n",
    " \n",
    "# Filter out the columns that are different.\n",
    "data3 = combined_data_1[different_cols]\n",
    " \n",
    "# Merge the DataFrames\n",
    "data = pd.merge(movie_budgets_df, data3, left_index=True,\n",
    "                     right_index=True, how='inner')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping of data features that I did not want to analyse.\n",
    "final_data = data.drop(['id','foreign_gross','movie_id','primary_title','start_year','year'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 cleaning of the final dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.0 fixing structural issues\n",
    "removal of the **$** from production_budget, domestic_gross and worldwide_gross\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['production_budget'] = final_data['production_budget'].str.replace('[\\$\\,]','',regex=True)\n",
    "final_data['domestic_gross'] = final_data['domestic_gross'].str.replace('[\\$\\,]','',regex=True)\n",
    "final_data['worldwide_gross'] = final_data['worldwide_gross'].str.replace('[\\$\\,]','',regex=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 changing data types \n",
    "production_budget, domestic_gross and worldwide_gross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['production_budget'] = pd.to_numeric(final_data['production_budget']) \n",
    "final_data['domestic_gross'] = pd.to_numeric(final_data['domestic_gross'])\n",
    "final_data['worldwide_gross'] = pd.to_numeric(final_data['worldwide_gross'])\n",
    "\n",
    "final_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(final_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.1 Profit Calculation\n",
    "\n",
    "I now want to discuss the relationship between a movie's budget and how much it earns at the box office. I'll focus on the **Domestic gross**, which includes all ticket sales revenue from US and Canadian theaters.\n",
    "\n",
    "I'll use the Pearson correlation coefficient to measure the linear correlation   between the production  budget and box office domestic gross.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result indicates a correlation of **0.6** between production budget and the domestic gross.\n",
    "This implies a **moderate** strength of relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['domestic_profit'] = final_data['domestic_gross'] - final_data['production_budget']\n",
    "correlation_df = final_data.iloc[:, [6,2,3,4,10]].head(13)\n",
    "correlation = final_data.corr()\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.heatmap(correlation, xticklabels = correlation.columns,\n",
    "            yticklabels = correlation.columns,\n",
    "            cmap = 'coolwarm', annot = True);\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.0.2 Genre Analysis\n",
    "\n",
    "#### How are genres changing over time?\n",
    "\n",
    "I've analyzed genre ties in this section. Because most of the movies in my datasets fit into more than one genre,it would be interesting to learn how the different types are related and perhaps check on how they affect the popularity of the movies compared against number votes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.sort_values(by='release_date', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_frequncy = dict(final_data['genres'].str.split(',', expand=True).stack().value_counts())\n",
    "genre_frequncy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize =(15, 12))\n",
    "explode = (0.0, 0.1, 0.2, 0.3, 0.2, 0.0,0.1,\n",
    "           0.0, 0.2, 0.3, 0.0, 0.0,0.1, 0.0,\n",
    "           0.2, 0.3, 0.5, 0.6,0.7, 0.8, 0.9, 1.0)\n",
    "\n",
    "plt.pie(genre_frequncy.values(), labels=genre_frequncy.keys(),\n",
    "        startangle=90, autopct='%.1f%%', colors=plt.cm.Set2.colors,\n",
    "        explode = explode)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drama movies had the highest frequency counts and it was the most distributed genre across the combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which genres have the highest correlation between budget and market success?\n",
    "\n",
    "To find the most expensive movies based on production budget, I sort my production budget in descending order and checked for the top 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am grouping my data by production budget to find out the top 100 expensive movies from my dataset then look into their genres to find out which genre appears most in the expensive movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_expensive_genre = final_data.sort_values(by=['production_budget'], ascending=False,).head(100)\n",
    "print('These are the top 10 most expensive movies from my dataset')\n",
    "top_expensive_genre.iloc[:,[6,1,2,3,4]].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_in_top_expensive_movies = dict(top_expensive_genre['genres'].str.split(',', expand=True).stack().value_counts())\n",
    "\n",
    "wordcloud = WordCloud(width = 800, height = 600,\n",
    "                     collocations = False, \n",
    "                      ).generate_from_frequencies(genres_in_top_expensive_movies)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(wordcloud);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates, top perfoming genres are also the top expensive movies to produce.This means that in  majority of the cases, a larger budget has also resulted in a higher domestic box office gross."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most of the movies in the dataset have multiple Genres, I decided to split each of them to have a count plot and see how they are distributed.\n",
    "From the value counts of the genres, drama had the highest value count while news had the least count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### average cost of producing movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_cost = final_data.iloc[:,[6,1,2,3,4]]\n",
    "print(f\"The average cost of producing a movie is {round(production_cost.production_budget.mean())} in USD\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.boxplot(x = 'production_budget', data = production_cost);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The average cost of producing a movie is {round(production_cost.production_budget.mean())} in USD\")\n",
    "print(f\"The average domestic gross {round(production_cost.domestic_gross.mean())} in USD\")\n",
    "print(f\"The average worldwide gross {round(production_cost.worldwide_gross.mean())} in USD\")\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "ax = sns.boxplot(data=production_cost, color='orange', dodge=False);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.3 Runtime Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=final_data[\"runtime_minutes\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_data['runtime_minutes'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average runtime of most movies was at 100 minutes.I decided to check how it has changed over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "sns.countplot(data=data['runtime_minutes'], x=data['year'])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its is clear, the runtime for movies has not changed over the yaers, much.Its still "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.4 Top movie stuido based on worlwide gross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"These are the top 15 movie studios from my dataset{pd.DataFrame(final_data.studio.value_counts()).head(15)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Drama, Comedy and Action are the top genres. As seen in the pie chart and wordcloud\n",
    "* Production budget and domestic gross have a high correlation.\n",
    "* Drama genre continues to dominate most of the movies being produced.\n",
    "* Runtime of movies has not greatly changed over the yaers as seen from the analysis.\n",
    "* Significant number of movies go into loss.\n",
    "* Movies that audience easily relates with are popular and have higher ratings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To enter into the film industry, it is important to consider short movies at an average of 50 minutes.\n",
    "\n",
    "* There are factors that affect the movie perfomance after it has been prodced these include release date and the streaming platforms.\n",
    "\n",
    "* More research could be done to understand what causes movies to be non profitable. This could help avoid loss in the movie industry."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
